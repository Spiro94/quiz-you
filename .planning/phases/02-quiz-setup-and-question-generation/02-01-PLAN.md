---
phase: 02-quiz-setup-and-question-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/002_quiz_schema.sql
  - src/types/database.ts
  - src/types/quiz.ts
  - src/lib/llm/types.ts
  - src/lib/llm/claude.ts
  - src/lib/llm/openai.ts
  - src/lib/llm/index.ts
  - src/lib/llm/prompts.ts
  - .env.local
  - .env.example
autonomous: true
requirements:
  - SETUP-01
  - SETUP-02
  - SETUP-03
  - SETUP-04

user_setup:
  - service: anthropic
    why: "Claude API key required for LLM question generation"
    env_vars:
      - name: VITE_ANTHROPIC_API_KEY
        source: "https://console.anthropic.com → API Keys → Create Key"
      - name: VITE_OPENAI_API_KEY
        source: "https://platform.openai.com/api-keys → Create new secret key (optional fallback)"
      - name: VITE_DEFAULT_LLM_PROVIDER
        source: "Set to 'anthropic' in .env.local (or 'openai' if using OpenAI fallback)"

must_haves:
  truths:
    - "quiz_sessions table exists in Supabase with RLS restricting users to their own sessions"
    - "quiz_questions table exists in Supabase with RLS restricting users to questions in their own sessions"
    - "topics table exists in Supabase populated with at least 10 programming languages/technologies"
    - "TypeScript types for quiz_sessions, quiz_questions, and topics tables are defined and accurate"
    - "LLMProvider interface with generateQuestion() and generateQuestionStream() methods is defined"
    - "ClaudeProvider class implements LLMProvider using @anthropic-ai/sdk with claude-opus-4-6 model"
    - "OpenAIProvider class implements LLMProvider as a fallback option"
    - "getLLMProvider() factory function reads VITE_DEFAULT_LLM_PROVIDER and returns the correct provider"
    - "Zod enums for Difficulty, QuestionType, QuestionCount are exported from src/types/quiz.ts"
  artifacts:
    - path: "supabase/migrations/002_quiz_schema.sql"
      provides: "SQL migration creating quiz_sessions, quiz_questions, topics tables with RLS and indexes"
      contains: "ENABLE ROW LEVEL SECURITY"
    - path: "src/types/quiz.ts"
      provides: "Zod schemas and TypeScript types for quiz domain (QuizSetupSchema, GeneratedQuestionSchema, enums)"
      exports: ["QuizSetupSchema", "QuizSetupFormData", "GeneratedQuestionSchema", "GeneratedQuestion", "Difficulty", "QuestionType", "AVAILABLE_TOPICS"]
    - path: "src/lib/llm/types.ts"
      provides: "LLMProvider interface and QuestionGenerationParams type"
      exports: ["LLMProvider", "QuestionGenerationParams"]
    - path: "src/lib/llm/claude.ts"
      provides: "Anthropic Claude implementation of LLMProvider"
      exports: ["ClaudeProvider"]
    - path: "src/lib/llm/openai.ts"
      provides: "OpenAI implementation of LLMProvider (fallback)"
      exports: ["OpenAIProvider"]
    - path: "src/lib/llm/index.ts"
      provides: "Factory function returning configured LLM provider"
      exports: ["getLLMProvider"]
    - path: "src/lib/llm/prompts.ts"
      provides: "Versioned question generation prompt builder"
      exports: ["buildQuestionPrompt"]
    - path: "src/types/database.ts"
      provides: "Extended Database interface including quiz_sessions, quiz_questions, topics tables"
  key_links:
    - from: "supabase/migrations/002_quiz_schema.sql"
      to: "public.quiz_sessions"
      via: "CREATE TABLE + ENABLE ROW LEVEL SECURITY + CREATE POLICY"
      pattern: "quiz_sessions.*user_id.*auth.uid"
    - from: "src/lib/llm/index.ts"
      to: "src/lib/llm/claude.ts"
      via: "getLLMProvider() factory reads VITE_DEFAULT_LLM_PROVIDER env var"
      pattern: "VITE_DEFAULT_LLM_PROVIDER"
    - from: "src/lib/llm/prompts.ts"
      to: "src/lib/llm/types.ts"
      via: "buildQuestionPrompt accepts QuestionGenerationParams"
      pattern: "QuestionGenerationParams"
    - from: "src/types/database.ts"
      to: "supabase/migrations/002_quiz_schema.sql"
      via: "TypeScript interface mirrors SQL table columns for quiz_sessions and quiz_questions"
      pattern: "quiz_sessions|quiz_questions"
---

<objective>
Create the database schema for quiz sessions and questions, populate the topics reference table, and build the LLM provider abstraction layer (Claude primary, OpenAI fallback). This plan is pure infrastructure — no UI. Every subsequent plan in Phase 2 depends on these types, tables, and the LLM client.

Purpose: SETUP-01 through SETUP-04 require a schema that can store session configuration (topics, difficulty, question types, count). The LLM abstraction is needed by Plan 02-03 (question generation) and must exist before any quiz flow can work.

Output:
- supabase/migrations/002_quiz_schema.sql: quiz_sessions, quiz_questions, topics tables with full RLS
- src/types/database.ts: extended with quiz table types
- src/types/quiz.ts: Zod schemas for all quiz domain types (setup form, generated questions, enums)
- src/lib/llm/: complete provider abstraction (types, claude, openai, index, prompts)
- .env.local: updated with ANTHROPIC/OPENAI keys and DEFAULT_LLM_PROVIDER
</objective>

<execution_context>
@/Users/danielvillamizar/.claude/get-shit-done/workflows/execute-plan.md
@/Users/danielvillamizar/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-quiz-setup-and-question-generation/02-RESEARCH.md
@.planning/phases/01-authentication-foundation/01-01-SUMMARY.md

Stack (locked): React 19, Vite 8, Tailwind CSS, Supabase (auth + database).
Existing packages: @supabase/supabase-js, react-router-dom, zod already installed.
Auth pattern: useAuth() hook from src/context/AuthContext.tsx provides user.id.
DB pattern: RLS policies use (SELECT auth.uid()) subquery form — evaluated once per query (established in 01-01).
LLM: Claude Opus 4.6 (primary), OpenAI (fallback). Per project decision: provider must be switchable.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install LLM dependencies and extend environment config</name>
  <files>
    package.json
    .env.local
    .env.example
  </files>
  <action>
    1. Install required packages:
       ```bash
       npm install @anthropic-ai/sdk openai @hookform/resolvers react-hook-form @tanstack/react-query @monaco-editor/react markdown-it
       npm install --save-dev @types/markdown-it
       ```
       - @anthropic-ai/sdk: Official Anthropic Claude client with streaming support
       - openai: OpenAI client for fallback provider
       - @hookform/resolvers: Zod resolver for React Hook Form (Plan 02-02)
       - react-hook-form: Form state management (Plan 02-02)
       - @tanstack/react-query: Server state management for quiz sessions
       - @monaco-editor/react: Code editor for coding problem answers (Plan 02-04)
       - markdown-it + @types/markdown-it: Markdown rendering for question text (Plan 02-04)

    2. Add LLM provider keys to .env.local (below existing Supabase vars):
       ```
       # LLM Provider Configuration
       VITE_ANTHROPIC_API_KEY=sk-ant-...
       VITE_OPENAI_API_KEY=sk-...
       VITE_DEFAULT_LLM_PROVIDER=anthropic
       ```
       NOTE: If the user has not yet provided API keys, add placeholder values now and note in the task output that keys must be filled before Plan 02-03 runs.

    3. Add corresponding placeholders to .env.example:
       ```
       # LLM Provider Configuration
       # Primary: get from https://console.anthropic.com → API Keys
       VITE_ANTHROPIC_API_KEY=sk-ant-your-key-here
       # Fallback: get from https://platform.openai.com/api-keys
       VITE_OPENAI_API_KEY=sk-your-key-here
       # Set to 'anthropic' or 'openai'
       VITE_DEFAULT_LLM_PROVIDER=anthropic
       ```

    CRITICAL: Never commit .env.local. Verify .gitignore still covers it.
  </action>
  <verify>
    - Run: `npm ls @anthropic-ai/sdk openai react-hook-form @hookform/resolvers @tanstack/react-query @monaco-editor/react markdown-it` — all should show installed versions
    - Run: `cat .env.example | grep ANTHROPIC` — should show placeholder key line
    - Run: `cat .gitignore | grep env.local` — should confirm .env.local is gitignored
  </verify>
  <done>
    - All 7 packages installed and in package.json dependencies
    - .env.local has VITE_ANTHROPIC_API_KEY, VITE_OPENAI_API_KEY, VITE_DEFAULT_LLM_PROVIDER
    - .env.example has placeholder values for all three new vars
    - .gitignore still covers .env.local
  </done>
</task>

<task type="auto">
  <name>Task 2: Create quiz database migration and extend TypeScript types</name>
  <files>
    supabase/migrations/002_quiz_schema.sql
    src/types/database.ts
  </files>
  <action>
    1. Create `supabase/migrations/002_quiz_schema.sql`:

    ```sql
    -- Migration: 002_quiz_schema
    -- Creates quiz_sessions, quiz_questions, and topics tables.
    -- All tables have RLS enabled per project security policy.
    -- RLS policies use (SELECT auth.uid()) subquery form for O(1) evaluation (established in 001).

    -- Available topics/technologies for quiz configuration
    CREATE TABLE IF NOT EXISTS public.topics (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      name TEXT NOT NULL UNIQUE,
      category TEXT NOT NULL CHECK (category IN ('language', 'framework', 'tool', 'concept')),
      created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

    -- Seed topics: minimum viable list for launch
    INSERT INTO public.topics (name, category) VALUES
      ('JavaScript', 'language'),
      ('TypeScript', 'language'),
      ('Python', 'language'),
      ('Dart', 'language'),
      ('Go', 'language'),
      ('Rust', 'language'),
      ('Java', 'language'),
      ('SQL', 'language'),
      ('React', 'framework'),
      ('Flutter', 'framework'),
      ('Node.js', 'framework'),
      ('Next.js', 'framework'),
      ('System Design', 'concept'),
      ('Data Structures', 'concept'),
      ('Algorithms', 'concept')
    ON CONFLICT (name) DO NOTHING;

    -- NOTE: topics is public read — no RLS needed (it's reference data, not user data)

    -- Quiz session configuration and tracking
    CREATE TABLE IF NOT EXISTS public.quiz_sessions (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
      topics TEXT[] NOT NULL,
      difficulty TEXT NOT NULL CHECK (difficulty IN ('beginner', 'normal', 'advanced')),
      question_types TEXT[] NOT NULL,
      question_count INT NOT NULL CHECK (question_count IN (5, 10, 20)),
      status TEXT NOT NULL DEFAULT 'in_progress' CHECK (status IN ('in_progress', 'completed', 'abandoned')),
      created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
      updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

    -- RLS: Users can only access their own sessions
    ALTER TABLE public.quiz_sessions ENABLE ROW LEVEL SECURITY;

    CREATE POLICY "quiz_sessions_select_own"
      ON public.quiz_sessions FOR SELECT
      TO authenticated
      USING ((SELECT auth.uid()) = user_id);

    CREATE POLICY "quiz_sessions_insert_own"
      ON public.quiz_sessions FOR INSERT
      TO authenticated
      WITH CHECK ((SELECT auth.uid()) = user_id);

    CREATE POLICY "quiz_sessions_update_own"
      ON public.quiz_sessions FOR UPDATE
      TO authenticated
      USING ((SELECT auth.uid()) = user_id)
      WITH CHECK ((SELECT auth.uid()) = user_id);

    -- Index for fast session lookups by user
    CREATE INDEX IF NOT EXISTS idx_quiz_sessions_user_id ON public.quiz_sessions(user_id);
    CREATE INDEX IF NOT EXISTS idx_quiz_sessions_status ON public.quiz_sessions(status);

    -- LLM-generated questions for a session (immutable after creation)
    CREATE TABLE IF NOT EXISTS public.quiz_questions (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      session_id UUID NOT NULL REFERENCES public.quiz_sessions(id) ON DELETE CASCADE,
      question_index INT NOT NULL,
      title TEXT NOT NULL,
      body TEXT NOT NULL,
      type TEXT NOT NULL CHECK (type IN ('coding', 'theoretical')),
      difficulty TEXT NOT NULL CHECK (difficulty IN ('beginner', 'normal', 'advanced')),
      topic TEXT NOT NULL,
      expected_format TEXT,
      created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
      UNIQUE (session_id, question_index)
    );

    -- RLS: Users can only access questions in their own sessions
    ALTER TABLE public.quiz_questions ENABLE ROW LEVEL SECURITY;

    CREATE POLICY "quiz_questions_select_own"
      ON public.quiz_questions FOR SELECT
      TO authenticated
      USING (EXISTS (
        SELECT 1 FROM public.quiz_sessions
        WHERE id = session_id
        AND user_id = (SELECT auth.uid())
      ));

    CREATE POLICY "quiz_questions_insert_own"
      ON public.quiz_questions FOR INSERT
      TO authenticated
      WITH CHECK (EXISTS (
        SELECT 1 FROM public.quiz_sessions
        WHERE id = session_id
        AND user_id = (SELECT auth.uid())
      ));

    -- Index for fast question retrieval by session
    CREATE INDEX IF NOT EXISTS idx_quiz_questions_session_id ON public.quiz_questions(session_id);

    -- Auto-update updated_at trigger for quiz_sessions
    CREATE OR REPLACE FUNCTION public.handle_quiz_session_updated_at()
    RETURNS TRIGGER AS $$
    BEGIN
      NEW.updated_at = NOW();
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;

    DROP TRIGGER IF EXISTS on_quiz_session_updated ON public.quiz_sessions;
    CREATE TRIGGER on_quiz_session_updated
      BEFORE UPDATE ON public.quiz_sessions
      FOR EACH ROW EXECUTE FUNCTION public.handle_quiz_session_updated_at();
    ```

    2. Apply this migration in Supabase Dashboard → SQL Editor → New query → paste → Run.
       Verify: no errors, tables appear in Table Editor.

    3. Extend `src/types/database.ts` to add quiz tables below the existing `users` table entry:

    Add inside the `Tables` block (after the closing brace of `users`):
    ```typescript
      quiz_sessions: {
        Row: {
          id: string
          user_id: string
          topics: string[]
          difficulty: 'beginner' | 'normal' | 'advanced'
          question_types: string[]
          question_count: 5 | 10 | 20
          status: 'in_progress' | 'completed' | 'abandoned'
          created_at: string
          updated_at: string
        }
        Insert: {
          id?: string
          user_id: string
          topics: string[]
          difficulty: 'beginner' | 'normal' | 'advanced'
          question_types: string[]
          question_count: 5 | 10 | 20
          status?: 'in_progress' | 'completed' | 'abandoned'
          created_at?: string
          updated_at?: string
        }
        Update: {
          topics?: string[]
          difficulty?: 'beginner' | 'normal' | 'advanced'
          question_types?: string[]
          question_count?: 5 | 10 | 20
          status?: 'in_progress' | 'completed' | 'abandoned'
          updated_at?: string
        }
      }
      quiz_questions: {
        Row: {
          id: string
          session_id: string
          question_index: number
          title: string
          body: string
          type: 'coding' | 'theoretical'
          difficulty: 'beginner' | 'normal' | 'advanced'
          topic: string
          expected_format: string | null
          created_at: string
        }
        Insert: {
          id?: string
          session_id: string
          question_index: number
          title: string
          body: string
          type: 'coding' | 'theoretical'
          difficulty: 'beginner' | 'normal' | 'advanced'
          topic: string
          expected_format?: string | null
          created_at?: string
        }
        Update: {
          title?: string
          body?: string
          expected_format?: string | null
        }
      }
      topics: {
        Row: {
          id: string
          name: string
          category: 'language' | 'framework' | 'tool' | 'concept'
          created_at: string
        }
        Insert: {
          id?: string
          name: string
          category: 'language' | 'framework' | 'tool' | 'concept'
          created_at?: string
        }
        Update: {
          name?: string
          category?: 'language' | 'framework' | 'tool' | 'concept'
        }
      }
    ```

    Also add convenience type aliases at the bottom of the file:
    ```typescript
    export type QuizSessionRow = Database['public']['Tables']['quiz_sessions']['Row']
    export type QuizSessionInsert = Database['public']['Tables']['quiz_sessions']['Insert']
    export type QuizQuestionRow = Database['public']['Tables']['quiz_questions']['Row']
    export type QuizQuestionInsert = Database['public']['Tables']['quiz_questions']['Insert']
    export type TopicRow = Database['public']['Tables']['topics']['Row']
    ```
  </action>
  <verify>
    - In Supabase Dashboard → Table Editor: verify quiz_sessions, quiz_questions, topics all appear
    - In Supabase Dashboard → Authentication → Policies: verify quiz_sessions has 3 policies, quiz_questions has 2 policies
    - In Supabase Table Editor → topics: verify 15 rows seeded (JavaScript, TypeScript, Python, etc.)
    - Run: `npx tsc --noEmit` — should pass with no errors
  </verify>
  <done>
    - quiz_sessions table exists with user_id, topics (TEXT[]), difficulty, question_types (TEXT[]), question_count, status, timestamps
    - quiz_questions table exists with session_id FK, question_index, title, body, type, difficulty, topic, expected_format
    - topics table seeded with 15 entries
    - RLS enabled on quiz_sessions (3 policies) and quiz_questions (2 policies)
    - All indexes created (idx_quiz_sessions_user_id, idx_quiz_sessions_status, idx_quiz_questions_session_id)
    - src/types/database.ts exports QuizSessionRow, QuizSessionInsert, QuizQuestionRow, QuizQuestionInsert, TopicRow
    - TypeScript compiles cleanly
  </done>
</task>

<task type="auto">
  <name>Task 3: Build LLM provider abstraction layer and quiz type definitions</name>
  <files>
    src/types/quiz.ts
    src/lib/llm/types.ts
    src/lib/llm/prompts.ts
    src/lib/llm/claude.ts
    src/lib/llm/openai.ts
    src/lib/llm/index.ts
  </files>
  <action>
    Create the following files in order:

    **src/types/quiz.ts** — Zod schemas and TypeScript types for the quiz domain:
    ```typescript
    // src/types/quiz.ts
    // Zod schemas and TypeScript types for quiz configuration and generated questions.
    // These are the single source of truth for form validation (Plan 02-02) and
    // LLM output validation (Plan 02-03).
    import { z } from 'zod'

    // Available programming languages and technologies
    // Mirrors the topics seeded in 002_quiz_schema.sql
    export const AVAILABLE_TOPICS = [
      'JavaScript', 'TypeScript', 'Python', 'Dart', 'Go', 'Rust', 'Java', 'SQL',
      'React', 'Flutter', 'Node.js', 'Next.js',
      'System Design', 'Data Structures', 'Algorithms'
    ] as const

    export const DifficultyEnum = z.enum(['beginner', 'normal', 'advanced'])
    export type Difficulty = z.infer<typeof DifficultyEnum>

    export const QuestionTypeEnum = z.enum(['coding', 'theoretical'])
    export type QuestionType = z.infer<typeof QuestionTypeEnum>

    export const QuestionCountEnum = z.enum(['5', '10', '20'])
    export type QuestionCount = z.infer<typeof QuestionCountEnum>

    // Schema for the quiz setup form (used by React Hook Form + Zod resolver in Plan 02-02)
    export const QuizSetupSchema = z.object({
      topics: z.array(z.string()).min(1, 'Select at least one topic'),
      difficulty: DifficultyEnum,
      questionTypes: z.array(QuestionTypeEnum).min(1, 'Select at least one question type'),
      questionCount: QuestionCountEnum
    })
    export type QuizSetupFormData = z.infer<typeof QuizSetupSchema>

    // Schema for validating LLM-generated question output
    // The LLM must return a JSON object conforming to this schema
    export const GeneratedQuestionSchema = z.object({
      title: z.string().min(10, 'Question title too short').max(300),
      body: z.string().min(50, 'Question body too short'),
      type: QuestionTypeEnum,
      difficulty: DifficultyEnum,
      topic: z.string().min(1),
      expectedFormat: z.string().optional()
    })
    export type GeneratedQuestion = z.infer<typeof GeneratedQuestionSchema>
    ```

    **src/lib/llm/types.ts** — LLMProvider interface:
    ```typescript
    // src/lib/llm/types.ts
    // Core interface that all LLM provider implementations must satisfy.
    // Per project decision: provider must be switchable without changing consumer code.
    import type { Difficulty, QuestionType } from '../../types/quiz'

    export interface QuestionGenerationParams {
      topics: string[]
      difficulty: Difficulty
      types: QuestionType[]
      sessionId: string     // Used to avoid question repetition within a session
      questionIndex: number // Position in session (for context)
    }

    export interface LLMProvider {
      // Non-streaming: returns complete question JSON string
      generateQuestion(params: QuestionGenerationParams): Promise<string>
      // Streaming: yields text chunks as they arrive from the LLM
      generateQuestionStream(params: QuestionGenerationParams): AsyncIterable<string>
    }
    ```

    **src/lib/llm/prompts.ts** — Versioned prompt builder:
    ```typescript
    // src/lib/llm/prompts.ts
    // Versioned question generation prompts.
    // Version is included in the prompt so output can be traced to a specific prompt version.
    // Update PROMPT_VERSION when changing the prompt to enable A/B tracking.
    import type { QuestionGenerationParams } from './types'

    export const PROMPT_VERSION = 'v1.0'

    export function buildQuestionPrompt(params: QuestionGenerationParams): string {
      const { topics, difficulty, types } = params
      const topicList = topics.join(', ')
      const typeList = types.includes('coding') && types.includes('theoretical')
        ? 'either a coding problem or a theoretical question (choose based on what best tests the topic)'
        : types.includes('coding')
          ? 'a coding problem requiring a code solution'
          : 'a theoretical question requiring a written explanation'

      const difficultyGuide = {
        beginner: 'suitable for developers with 0-1 years of experience. Focus on fundamentals, basic syntax, and simple concepts.',
        normal: 'suitable for developers with 1-3 years of experience. Include real-world scenarios and moderate complexity.',
        advanced: 'suitable for developers with 3+ years of experience. Cover edge cases, performance considerations, and architectural decisions.'
      }[difficulty]

      return `You are a technical interviewer generating a single interview question.

Generate ${typeList} about one of these topics: ${topicList}
Difficulty level: ${difficulty} — ${difficultyGuide}

IMPORTANT: Return ONLY a valid JSON object. No markdown fences, no explanation, no preamble.

Required JSON structure:
{
  "title": "Brief question title (10-200 chars)",
  "body": "Full question text with context (50-1500 chars). For coding questions include the problem statement, constraints, and example inputs/outputs. For theoretical questions include the scenario or concept to explain.",
  "type": "${types.length === 1 ? types[0] : 'coding or theoretical'}",
  "difficulty": "${difficulty}",
  "topic": "The specific topic from [${topicList}] this question covers",
  "expectedFormat": "e.g. 'Python function', 'Paragraph explanation', 'SQL query'"
}

Prompt version: ${PROMPT_VERSION}`
    }
    ```

    **src/lib/llm/claude.ts** — Anthropic Claude implementation:
    ```typescript
    // src/lib/llm/claude.ts
    // Anthropic Claude implementation of LLMProvider.
    // Uses claude-opus-4-6 as specified in project decisions (highest reasoning, 92% HumanEval).
    import Anthropic from '@anthropic-ai/sdk'
    import { buildQuestionPrompt } from './prompts'
    import type { LLMProvider, QuestionGenerationParams } from './types'

    export class ClaudeProvider implements LLMProvider {
      private client: Anthropic

      constructor(apiKey: string) {
        this.client = new Anthropic({
          apiKey,
          dangerouslyAllowBrowser: true // Required for Vite client-side usage
        })
      }

      async generateQuestion(params: QuestionGenerationParams): Promise<string> {
        const prompt = buildQuestionPrompt(params)
        const message = await this.client.messages.create({
          model: 'claude-opus-4-6',
          max_tokens: 1024,
          messages: [{ role: 'user', content: prompt }]
        })
        const content = message.content[0]
        if (content.type !== 'text') throw new Error('Unexpected LLM response type')
        return content.text
      }

      async *generateQuestionStream(params: QuestionGenerationParams): AsyncIterable<string> {
        const prompt = buildQuestionPrompt(params)
        const stream = this.client.messages.stream({
          model: 'claude-opus-4-6',
          max_tokens: 1024,
          messages: [{ role: 'user', content: prompt }]
        })

        for await (const chunk of stream) {
          if (
            chunk.type === 'content_block_delta' &&
            chunk.delta.type === 'text_delta'
          ) {
            yield chunk.delta.text
          }
        }
      }
    }
    ```

    **src/lib/llm/openai.ts** — OpenAI fallback implementation:
    ```typescript
    // src/lib/llm/openai.ts
    // OpenAI fallback implementation of LLMProvider.
    // Used when VITE_DEFAULT_LLM_PROVIDER=openai or as a backup if Anthropic is unavailable.
    import OpenAI from 'openai'
    import { buildQuestionPrompt } from './prompts'
    import type { LLMProvider, QuestionGenerationParams } from './types'

    export class OpenAIProvider implements LLMProvider {
      private client: OpenAI

      constructor(apiKey: string) {
        this.client = new OpenAI({
          apiKey,
          dangerouslyAllowBrowser: true // Required for Vite client-side usage
        })
      }

      async generateQuestion(params: QuestionGenerationParams): Promise<string> {
        const prompt = buildQuestionPrompt(params)
        const response = await this.client.chat.completions.create({
          model: 'gpt-4o',
          max_tokens: 1024,
          messages: [{ role: 'user', content: prompt }]
        })
        return response.choices[0]?.message?.content ?? ''
      }

      async *generateQuestionStream(params: QuestionGenerationParams): AsyncIterable<string> {
        const prompt = buildQuestionPrompt(params)
        const stream = await this.client.chat.completions.create({
          model: 'gpt-4o',
          max_tokens: 1024,
          stream: true,
          messages: [{ role: 'user', content: prompt }]
        })

        for await (const chunk of stream) {
          const delta = chunk.choices[0]?.delta?.content
          if (delta) yield delta
        }
      }
    }
    ```

    **src/lib/llm/index.ts** — Factory function:
    ```typescript
    // src/lib/llm/index.ts
    // Factory function that reads VITE_DEFAULT_LLM_PROVIDER and returns the configured provider.
    // Switching providers requires only a .env.local change — no code changes.
    import { ClaudeProvider } from './claude'
    import { OpenAIProvider } from './openai'
    import type { LLMProvider } from './types'

    export type { LLMProvider, QuestionGenerationParams } from './types'

    export function getLLMProvider(): LLMProvider {
      const provider = import.meta.env.VITE_DEFAULT_LLM_PROVIDER || 'anthropic'

      if (provider === 'openai') {
        const apiKey = import.meta.env.VITE_OPENAI_API_KEY
        if (!apiKey) throw new Error('VITE_OPENAI_API_KEY not set in .env.local')
        return new OpenAIProvider(apiKey)
      }

      const apiKey = import.meta.env.VITE_ANTHROPIC_API_KEY
      if (!apiKey) throw new Error('VITE_ANTHROPIC_API_KEY not set in .env.local')
      return new ClaudeProvider(apiKey)
    }
    ```
  </action>
  <verify>
    - Run: `npx tsc --noEmit` — should compile with zero errors across all new files
    - Run: `node -e "const {z}=require('zod'); console.log('zod ok')"` then check that QuizSetupSchema can be imported from src/types/quiz.ts
    - Manually review src/lib/llm/index.ts — getLLMProvider() should throw a descriptive error when API key is missing (not a cryptic SDK error)
    - Check that buildQuestionPrompt() output contains 'Prompt version: v1.0' and references the difficulty guide text
  </verify>
  <done>
    - src/types/quiz.ts exports: AVAILABLE_TOPICS (15 items), DifficultyEnum, QuestionTypeEnum, QuestionCountEnum, QuizSetupSchema, QuizSetupFormData, GeneratedQuestionSchema, GeneratedQuestion
    - src/lib/llm/types.ts exports: QuestionGenerationParams, LLMProvider (interface)
    - src/lib/llm/prompts.ts exports: buildQuestionPrompt, PROMPT_VERSION = 'v1.0'
    - src/lib/llm/claude.ts exports: ClaudeProvider (implements LLMProvider with claude-opus-4-6)
    - src/lib/llm/openai.ts exports: OpenAIProvider (implements LLMProvider with gpt-4o)
    - src/lib/llm/index.ts exports: getLLMProvider() factory reading VITE_DEFAULT_LLM_PROVIDER
    - TypeScript compiles cleanly (npx tsc --noEmit passes)
    - npm run build succeeds
  </done>
</task>

</tasks>

<verification>
After all tasks complete, verify end-to-end foundation:

1. Run `npm run build` — must succeed with zero TypeScript errors and no console warnings
2. In Supabase Dashboard → Table Editor: confirm quiz_sessions, quiz_questions, topics tables exist
3. In Supabase Dashboard → Authentication → Policies: confirm 3 policies on quiz_sessions, 2 on quiz_questions
4. In topics table: confirm 15 rows seeded (JavaScript through Algorithms)
5. Run: `npx tsc --noEmit` — clean compile with all new files in scope
6. Manual spot-check: open src/lib/llm/index.ts and confirm getLLMProvider() throws descriptive error if VITE_ANTHROPIC_API_KEY is empty string
</verification>

<success_criteria>
- quiz_sessions, quiz_questions, topics tables exist in Supabase with correct schemas and RLS
- Topics seeded with 15 programming languages/technologies
- All quiz TypeScript types compile cleanly (QuizSetupSchema, GeneratedQuestionSchema, enums)
- LLM abstraction layer functional: getLLMProvider() returns ClaudeProvider by default, OpenAIProvider when env var set to 'openai'
- VITE_ANTHROPIC_API_KEY present in .env.local and documented in .env.example
- npm run build passes cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/02-quiz-setup-and-question-generation/02-01-SUMMARY.md` documenting:
- Exact packages installed with versions
- Supabase table schemas as created (any deviations from plan)
- LLM provider decisions (e.g., why dangerouslyAllowBrowser is needed for Vite)
- PROMPT_VERSION used
- Any deviations from this plan
</output>
